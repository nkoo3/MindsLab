#Set search_words which you want to have the image of
search_words = [“Taylor Swift”]

#Specify the path where you want to download to
img_dir = “/Users/nancykoo/Desktop/Pictures”

#Repeat extracting for every words
for word in search_words:
  dir_path = img_dir + word
if not os.path.exists(dir_path):
  os.makedirs(dir_path)

#Make word suitable for URL
urlKeyword = parse.quote(word)

#Create url with target word
url = ‘https://www.google.com/search?hl=jp&q=' + urlKeyword + ‘&btnG=Google+Search&tbs=0&safe=off&tbm=isch’

#Headers is necessary when you send request
headers = {“User-Agent”: “Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0”,}

#Request is made with url and headers
request = req.Request(url=url, headers=headers)
page = req.urlopen(request)

#Page that you reveived into utf-8
html = page.read().decode(‘utf-8’)

#Use BeutifulSoup, “html.parser”. HTML object is available in Python.
html = bs4.BeautifulSoup(html, “html.parser”)

#.rg_meta.notranslate is for extracting data without permission(not sure)
elems = html.select(‘.rg_meta.notranslate’)

counter = 0
error_counter = 0

for ele in elems:
ele = ele.contents[0].replace(‘“‘,’’).split(‘,’)
eledict = dict()

#Image URL is indicated here
for e in ele:
num = e.find(‘:’)
eledict[e[0:num]] = e[num+1:]
imageURL = eledict[‘ou’]

#URL retrieve: Extract imageURL from file_path
#If error occurs, execute except program
try:
  file_path = dir_path + “/” + str(counter)+”.jpg”
  urlretrieve(imageURL, file_path)
  counter += 1
except Exception as e:
  error_counter += 1
if counter == 1:
  print(“Start downloading”, word)
if counter==200:
  break
  print(“{} errors occur out of ”.format(counter, error_counter))
